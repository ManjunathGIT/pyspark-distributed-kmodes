# pyspark-distributed-kmodes

## Installing

```
$ pip install .
```

TODO: update README

## Distributed K-modes for pySpark

There is an example ipython notebook that shows how to run the K-modes calculation.
 
This calculation depends on the pyspark_kmodes.py being in the Python import path.

I have tested this with Kmodes.py in the working directory - it needs to be in a place that is accessible for export to the worker nodes.

The two PDF files are the articles on which this approach is based - both the original and the distributed versions.  I've left them here for reference purposes, they are not important for functionality.

TODO: add links to papers instead of PDFs?


